{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T17:08:38.274736700Z",
     "start_time": "2023-09-13T17:08:38.261621600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import traceback\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from tqdm.notebook import tqdm\n",
    "from num2words import num2words\n",
    "# from qgis.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "<p style=\"text-align:center\"><span style=\"color:red\"><font size=\"140\"> <strong> Python Class <strong> </font></span></p>\n",
    "<p style=\"text-align:center\"><img src=\"pics\\fang-research-web-logo.png\" width=\"580\"></p><br>re\n",
    "<p style=\"text-align:center\"><img src=\"pics\\arcgispro.png\" width=1000px></p><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "<p style=\"text-align:center\"><span style=\"color:red\"><font size=\"140\"> <strong> Python Class <strong> </font></span></p>\n",
    "<p style=\"text-align:center\"><img src=\"pics\\arcgispro.png\" width=1000px></p><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T17:08:40.478506Z",
     "start_time": "2023-09-13T17:08:40.354541500Z"
    }
   },
   "outputs": [],
   "source": [
    "class GIS_To_SWMM:\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, workspace, SWMM_dir):\n",
    "\n",
    "        self.workspace = workspace\n",
    "        self.SWMM_dir = SWMM_dir\n",
    "        self.outWorkspace = os.path.join(os.getcwd(),\"GIS_Prepration.gdb\")\n",
    "        arcpy.env.workspace = self.workspace\n",
    "        env.overwriteOutput = True\n",
    "\n",
    "        self.GIS_junctions = None\n",
    "        self.GIS_storages = None\n",
    "        self.GIS_conduits = None\n",
    "        self.GIS_dividers = None\n",
    "        self.GIS_outfalls = None\n",
    "        self.GIS_orifices = None\n",
    "        self.GIS_outlets = None\n",
    "        self.GIS_pumps = None\n",
    "        self.GIS_weirs = None\n",
    "        self.GIS_subcatchments = None\n",
    "        self.SWMM_junctions = None\n",
    "        self.SWMM_storages = None\n",
    "        self.SWMM_conduits = None\n",
    "        self.SWMM_dividers = None\n",
    "        self.SWMM_outfalls = None\n",
    "        self.SWMM_orifices = None\n",
    "        self.SWMM_outlets = None\n",
    "        self.SWMM_pumps = None\n",
    "        self.SWMM_weirs = None\n",
    "        self.SWMM_subcatchments = None\n",
    "        self.GIS_Lines = None\n",
    "        self.GIS_Points = None\n",
    "\n",
    "\n",
    "\n",
    "    def read_data(self):\n",
    "\n",
    "        df = pd.DataFrame(columns = [\"GIS Founded Shapefiles\",\"Status\", \"SWMM Founded Shapefiles\", \"status\"])\n",
    "        GIS_feature_classes = pd.Series([\"GIS_junctions\",\n",
    "                                         \"GIS_storages\",\n",
    "                                         \"GIS_conduits\",\n",
    "                                         \"GIS_dividers\",\n",
    "                                         \"GIS_outfalls\",\n",
    "                                         \"GIS_orifices\",\n",
    "                                         \"GIS_outlets\",\n",
    "                                         \"GIS_pumps\",\n",
    "                                         \"GIS_weirs\",\n",
    "                                         \"GIS_subcatchments\"])\n",
    "        SWMM_feature_classes = pd.Series([\"SWMM_junctions\",\n",
    "                                          \"SWMM_storages\",\n",
    "                                          \"SWMM_conduits\",\n",
    "                                          \"SWMM_dividers\",\n",
    "                                          \"SWMM_outfalls\",\n",
    "                                          \"SWMM_orifices\",\n",
    "                                          \"SWMM_outlets\",\n",
    "                                          \"SWMM_pumps\",\n",
    "                                          \"SWMM_weirs\",\n",
    "                                          \"SWMM_subcatchments\"])\n",
    "        df[\"GIS Founded Shapefiles\"] = GIS_feature_classes\n",
    "        df[\"SWMM Founded Shapefiles\"] = SWMM_feature_classes\n",
    "        if arcpy.Exists(os.path.join(self.workspace, GIS_feature_classes[0])):\n",
    "            self.GIS_junctions = os.path.join(self.workspace, \"GIS_junctions\")\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[0],\"Status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[0],\"Status\"] = \"No data\"\n",
    "\n",
    "        if arcpy.Exists(os.path.join(self.workspace, GIS_feature_classes[1])):\n",
    "            self.GIS_storages = os.path.join(self.workspace, \"GIS_storages\")\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[1],\"Status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[1],\"Status\"] = \"No data\"\n",
    "\n",
    "        if arcpy.Exists(os.path.join(self.workspace, GIS_feature_classes[2])):\n",
    "            self.GIS_conduits = os.path.join(self.workspace, \"GIS_conduits\")\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[2],\"Status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[2],\"Status\"] = \"No data\"\n",
    "\n",
    "        if arcpy.Exists(os.path.join(self.workspace, GIS_feature_classes[3])):\n",
    "            self.GIS_dividers = os.path.join(self.workspace, \"GIS_dividers\")\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[3],\"Status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[3],\"Status\"] = \"No data\"\n",
    "\n",
    "        if arcpy.Exists(os.path.join(self.workspace, GIS_feature_classes[4])):\n",
    "            self.GIS_outfalls = os.path.join(self.workspace, \"GIS_outfalls\")\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[4],\"Status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[4],\"Status\"] = \"No data\"\n",
    "\n",
    "        if arcpy.Exists(os.path.join(self.workspace, GIS_feature_classes[5])):\n",
    "            self.GIS_orifices = os.path.join(self.workspace, \"GIS_orifices\")\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[5],\"Status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[5],\"Status\"] = \"No data\"\n",
    "\n",
    "        if arcpy.Exists(os.path.join(self.workspace, GIS_feature_classes[6])):\n",
    "            self.GIS_outlets = os.path.join(self.workspace, \"GIS_outlets\")\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[6],\"Status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[6],\"Status\"] = \"No data\"\n",
    "\n",
    "        if arcpy.Exists(os.path.join(self.workspace, GIS_feature_classes[7])):\n",
    "            self.GIS_pumps = os.path.join(self.workspace, \"GIS_pumps\")\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[7],\"Status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[7],\"Status\"] = \"No data\"\n",
    "\n",
    "        if arcpy.Exists(os.path.join(self.workspace, GIS_feature_classes[8])):\n",
    "            self.GIS_weirs = os.path.join(self.workspace, \"GIS_weirs\")\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[8],\"Status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[8],\"Status\"] = \"No data\"\n",
    "\n",
    "        if arcpy.Exists(os.path.join(self.workspace, GIS_feature_classes[9])):\n",
    "            self.GIS_subcatchments = os.path.join(self.workspace, \"GIS_subcatchments\")\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[9],\"Status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"GIS Founded Shapefiles\"] == GIS_feature_classes[9],\"Status\"] = \"No data\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if os.path.exists(os.path.join(self.SWMM_dir, SWMM_feature_classes[0]+\".shp\")):\n",
    "            self.SWMM_junctions = os.path.join(self.SWMM_dir, \"SWMM_junctions\"+\".shp\")\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[0],\"status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[0],\"status\"] = \"No data\"\n",
    "\n",
    "        if os.path.exists(os.path.join(self.SWMM_dir, SWMM_feature_classes[1]+\".shp\")):\n",
    "            self.SWMM_storages = os.path.join(self.SWMM_dir, \"SWMM_storages\"+\".shp\")\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[1],\"status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[1],\"status\"] = \"No data\"\n",
    "\n",
    "        if os.path.exists(os.path.join(self.SWMM_dir, SWMM_feature_classes[2]+\".shp\")):\n",
    "            self.SWMM_conduits = os.path.join(self.SWMM_dir, \"SWMM_conduits\"+\".shp\")\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[2],\"status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[2],\"status\"] = \"No data\"\n",
    "\n",
    "        if os.path.exists(os.path.join(self.SWMM_dir, SWMM_feature_classes[3]+\".shp\")):\n",
    "            self.SWMM_dividers = os.path.join(self.SWMM_dir, \"SWMM_dividers\"+\".shp\")\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[3],\"status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[3],\"status\"] = \"No data\"\n",
    "\n",
    "        if os.path.exists(os.path.join(self.SWMM_dir, SWMM_feature_classes[4]+\".shp\")):\n",
    "            self.SWMM_outfalls = os.path.join(self.SWMM_dir, \"SWMM_outfalls\"+\".shp\")\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[4],\"status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[4],\"status\"] = \"No data\"\n",
    "\n",
    "        if os.path.exists(os.path.join(self.SWMM_dir, SWMM_feature_classes[5]+\".shp\")):\n",
    "            self.SWMM_orifices = os.path.join(self.SWMM_dir, \"SWMM_orifices\"+\".shp\")\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[5],\"status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[5],\"status\"] = \"No data\"\n",
    "\n",
    "        if os.path.exists(os.path.join(self.SWMM_dir, SWMM_feature_classes[6]+\".shp\")):\n",
    "            self.SWMM_outlets = os.path.join(self.SWMM_dir, \"SWMM_outlets\"+\".shp\")\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[6],\"status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[6],\"status\"] = \"No data\"\n",
    "\n",
    "        if os.path.exists(os.path.join(self.SWMM_dir, SWMM_feature_classes[7]+\".shp\")):\n",
    "            self.SWMM_pumps = os.path.join(self.SWMM_dir, \"SWMM_pumps\"+\".shp\")\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[7],\"status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[7],\"status\"] = \"No data\"\n",
    "\n",
    "        if os.path.exists(os.path.join(self.SWMM_dir, SWMM_feature_classes[8]+\".shp\")):\n",
    "            self.SWMM_weirs = os.path.join(self.SWMM_dir, \"SWMM_weirs\"+\".shp\")\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[8],\"status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[8],\"status\"] = \"No data\"\n",
    "\n",
    "        if os.path.exists(os.path.join(self.SWMM_dir, SWMM_feature_classes[9]+\".shp\")):\n",
    "            self.SWMM_subcatchments = os.path.join(self.SWMM_dir, \"SWMM_subcatchments\"+\".shp\")\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[9],\"status\"] = \"Has been found\"\n",
    "        else:\n",
    "            df.loc[df[\"SWMM Founded Shapefiles\"] == SWMM_feature_classes[9],\"status\"] = \"No data\"\n",
    "        mask1 = df[\"Status\"] == \"Has been found\"\n",
    "        mask2 = df[\"GIS Founded Shapefiles\"].isin([\"GIS_junctions\", \"GIS_storages\", \"GIS_dividers\", \"GIS_outfalls\"])\n",
    "        self.GIS_Points = df[mask1 & mask2][\"GIS Founded Shapefiles\"].reset_index(drop = True)\n",
    "        mask3 = df[\"status\"] == \"Has been found\"\n",
    "        mask4 = df[\"GIS Founded Shapefiles\"].isin([\"GIS_conduits\", \"GIS_orifices\", \"GIS_outlets\", \"GIS_pumps\", \"GIS_weirs\"])\n",
    "        self.GIS_Lines = df[mask3 & mask4][\"GIS Founded Shapefiles\"].reset_index(drop = True)\n",
    "        return df\n",
    "\n",
    "\n",
    "    def consistent_lines_cdm(self, line_shapefile, point_shapfile, Snap_Radius):\n",
    "        if not arcpy.Exists(os.path.join(self.workspace, line_shapefile+\"_merged\")):\n",
    "            self.lines = os.path.join(self.workspace, \"lines\")\n",
    "        arcpy.Snap_edit(point_shapfile,\n",
    "                [[line_shapefile,\n",
    "                \"EDGE\",\n",
    "                Snap_Radius\n",
    "                    ]])\n",
    "        if not os.path.exists(os.path.join(os.getcwd(), \"GIS_Prepration.gdb\")):\n",
    "            arcpy.CreateFileGDB_management(os.getcwd(), \"GIS_Prepration.gdb\")\n",
    "        arcpy.management.UnsplitLine(line_shapefile, os.path.join(self.outWorkspace, \"lines_unsplited\"),\n",
    "                                    None,\n",
    "                                    None)\n",
    "        arcpy.management.SplitLineAtPoint(os.path.join(self.outWorkspace, \"lines_unsplited\"),point_shapfile,line_shapefile+\"_merged\", \"1 Feet\")\n",
    "        self.lines = os.path.join(self.workspace, line_shapefile+\"_merged\")\n",
    "        return\n",
    "\n",
    "    def consistent_lines(self, line_series, point_series, Snap_Radius):\n",
    "        env.overwriteOutput = True\n",
    "        line_shapefile = line_series.apply(lambda line_series : os.path.join(self.workspace , line_series))\n",
    "        point_shapfile = point_series.apply(lambda point_series : os.path.join(self.workspace, point_series))\n",
    "\n",
    "        for line in range(len(line_shapefile)):\n",
    "            for point in range(len(point_shapfile)):\n",
    "                print(line_shapefile[line].split(\"_\")[1] +\" based on \"+ point_shapfile[point].split(\"_\")[1])\n",
    "                arcpy.Snap_edit(point_shapfile[point],\n",
    "                [[line_shapefile[line],\n",
    "                  \"EDGE\",\n",
    "                  Snap_Radius\n",
    "                  ]])\n",
    "                print(\"are snaped\")\n",
    "\n",
    "\n",
    "        for line in range(len(line_shapefile)):\n",
    "            if not os.path.exists(os.path.join(os.getcwd(), \"GIS_Prepration.gdb\")):\n",
    "                arcpy.CreateFileGDB_management(os.getcwd(), \"GIS_Prepration.gdb\")\n",
    "            arcpy.management.UnsplitLine(line_shapefile[line], os.path.join(self.outWorkspace, \"lines_unsplited_0\"),None,None)\n",
    "            print(line_shapefile[line].split(\"_\")[1] + \" are merged\")\n",
    "            for point in range(len(point_shapfile)):\n",
    "                print(line_shapefile[line].split(\"_\")[1] +\" based on \"+ point_shapfile[point].split(\"_\")[1])\n",
    "                arcpy.management.SplitLineAtPoint(os.path.join(self.outWorkspace, \"lines_unsplited_\"+str(point)),point_shapfile[point],os.path.join(self.outWorkspace, \"lines_unsplited_\"+str(point+1)), \"1 Feet\")\n",
    "                arcpy.FeatureClassToFeatureClass_conversion(os.path.join(self.outWorkspace, \"lines_unsplited_\"+str(point+1)), self.workspace, \"GIS_\"+line_shapefile[line].split(\"_\")[1])\n",
    "                print(\"Splitted at \"+point_shapfile[point].split(\"_\")[1]+ \" points\")\n",
    "\n",
    "    def find_geometries(self, Shapefile):\n",
    "\n",
    "        df = pd.DataFrame(columns = [\"Feature ID\", \"Point_X\", \"Point_Y\"])\n",
    "        for row in arcpy.da.SearchCursor(Shapefile, [\"OID@\", \"SHAPE@\"]):\n",
    "\n",
    "            object_ID = f\"Feature {row[0]}\"\n",
    "            for pnt in row[1]:\n",
    "                coordinates = [f\"{pnt.X}, {pnt.Y}\"]\n",
    "                df.loc[row[0], \"Feature ID\"] = object_ID\n",
    "                df.loc[row[0], \"Point_X\"] = pnt.X\n",
    "                df.loc[row[0], \"Point_Y\"] = pnt.Y\n",
    "        df[[\"Point_X\",\"Point_Y\"]].astype(\"float\")\n",
    "        df.set_index(\"Feature ID\", inplace = True)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def find_distance(self, FID_List_Moving, FID_List_Staying, SWMM_Nodes = None, GIS_Nodes = None):\n",
    "        return self.find_geometries(SWMM_Nodes).loc[FID_List_Moving] - self.find_geometries(GIS_Nodes).loc[FID_List_Staying]\n",
    "\n",
    "\n",
    "    def shift_features(self, FID_List_Moving, FID_List_Staying, SWMM_Nodes = None, GIS_Nodes = None, rest = None):\n",
    "        arcpy.env.workspace = self.workspace\n",
    "        env.overwriteOutput = True\n",
    "        print(\"A backup of all shapefiles have been stored\")\n",
    "        \"\"\"\n",
    "        Shifts features by an x and/or y value. The shift values are in\n",
    "        the units of the in_features coordinate system.\n",
    "\n",
    "        Parameters:\n",
    "        in_features: string\n",
    "            An existing feature class or feature layer.  If using a\n",
    "            feature layer with a selection, only the selected features\n",
    "            will be modified.\n",
    "\n",
    "        x_shift: float\n",
    "            The distance the x coordinates will be shifted.\n",
    "\n",
    "        y_shift: float\n",
    "            The distance the y coordinates will be shifted.\n",
    "        \"\"\"\n",
    "        if SWMM_Nodes == None:\n",
    "            SWMM_Nodes = self.SWMM_junctions\n",
    "\n",
    "        if GIS_Nodes == None:\n",
    "            GIS_Nodes = self.GIS_junctions\n",
    "        dists_x = self.find_distance (FID_List_Moving, FID_List_Staying, SWMM_Nodes, GIS_Nodes)[0]\n",
    "        dists_y = self.find_distance (FID_List_Moving, FID_List_Staying, SWMM_Nodes, GIS_Nodes)[1]\n",
    "        print(\"X Distance of \" + FID_List_Moving + \" in \" + SWMM_Nodes.split(\"_\")[1] + \" has been calculated as \" + str(dists_x))\n",
    "        print(\"Y Distance of \" + FID_List_Moving + \" in \" + SWMM_Nodes.split(\"_\")[1] + \" has been calculated as \" + str(dists_y))\n",
    "\n",
    "        with arcpy.da.UpdateCursor(SWMM_Nodes, ['SHAPE@XY']) as cursor:\n",
    "            for row in cursor:\n",
    "\n",
    "                cursor.updateRow([[row[0][0] - (dists_x or 0),\n",
    "                                   row[0][1] - (dists_y or 0)]])\n",
    "            # print(\"Distance between \"+FID_List_Moving+\" and \"+FID_List_Staying+\" is \"+str(dists_x, dists_y))\n",
    "            # print(str(dists_x))\n",
    "            # print(str(dists_y))\n",
    "\n",
    "\n",
    "        for sf in range(len(rest)):\n",
    "            with arcpy.da.UpdateCursor(rest[sf], ['SHAPE@XY']) as cursor:\n",
    "                for row in cursor:\n",
    "                    print(\"Moving \"+ rest[sf].split(\"_\")[1])\n",
    "                    # print(\"Distance between \"+FID_List_Moving[FID]+\" and \"+FID_List_Staying[FID]+\" is \"+self.find_distance (FID_List_Moving[FID], FID_List_Staying[FID], SWMM_Nodes, GIS_Nodes))\n",
    "                    cursor.updateRow([[row[0][0] - (dists_x or 0),\n",
    "                                       row[0][1] - (dists_y or 0)]])\n",
    "\n",
    "        return\n",
    "    def spatial_join_points(self,GIS_Feature = None, SWMM_Feature = None):\n",
    "\n",
    "        if not os.path.exists(os.path.join(os.getcwd(), \"GIS_Prepration.gdb\")):\n",
    "                arcpy.CreateFileGDB_management(os.getcwd(), \"GIS_Prepration.gdb\")\n",
    "\n",
    "        df = pd.DataFrame(columns = [\"Name\",\"Radius\", \"Unique_Features\"])\n",
    "        pbar = tqdm(range(1,5))\n",
    "        for i in pbar:\n",
    "            radius = f\"{i} Feet\"\n",
    "            pbar.set_description(f\"{os.path.basename(GIS_Feature)[4:]} are being joined with Radius {radius} --> \")\n",
    "            temp_sp_names = os.path.join(self.outWorkspace,f\"{os.path.basename(GIS_Feature)}_spa_{i}\")\n",
    "            arcpy.analysis.SpatialJoin(GIS_Feature, SWMM_Feature, temp_sp_names,\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", \"CLOSEST\", radius, '#')\n",
    "            arcpy.FeatureClassToShapefile_conversion(temp_sp_names, os.getcwd())\n",
    "            table = gpd.read_file(os.path.join(os.getcwd(),os.path.basename(temp_sp_names)+\".shp\"))\n",
    "            # table[table.columns[:-1]] =  table[table.columns[:-1]].fillna(value='<Null>')\n",
    "            # dups_shape = table[\"Name\"].nunique()\n",
    "            # dups_shape[dups_shape != 1].sum()\n",
    "            df.loc[i,\"Name\"] = f\"{os.path.basename(GIS_Feature)}_spa_{i}\"\n",
    "            df.loc[i,\"Radius\"] = radius\n",
    "            df.loc[i,\"Unique_Features\"] = table[\"Name\"].nunique()\n",
    "            arcpy.Delete_management(os.path.join(os.getcwd(),os.path.basename(temp_sp_names)+\".shp\"))\n",
    "\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def spatial_join_lines(self, GIS_Feature = None, SWMM_Feature = None, methode = None):\n",
    "\n",
    "        if not os.path.exists(os.path.join(os.getcwd(), \"GIS_Prepration.gdb\")):\n",
    "                arcpy.CreateFileGDB_management(os.getcwd(), \"GIS_Prepration.gdb\")\n",
    "\n",
    "        df = pd.DataFrame(columns = [\"Name\",\"Radius\", \"Unique Features\"])\n",
    "        pbar = tqdm(range(1,2))\n",
    "        for i in pbar:\n",
    "            temp_sp_names = os.path.join(self.outWorkspace,f\"{os.path.basename(GIS_Feature)}_spa_{i}\")\n",
    "            radius = f\"{i} Feet\"\n",
    "            arcpy.analysis.SpatialJoin(GIS_Feature, SWMM_Feature, temp_sp_names,\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", methode, radius, '#')\n",
    "            arcpy.FeatureClassToShapefile_conversion(temp_sp_names, os.getcwd())\n",
    "            table = gpd.read_file(os.path.join(os.getcwd(),os.path.basename(temp_sp_names)+\".shp\"))\n",
    "            # table[table.columns[:-1]] =  table[table.columns[:-1]].fillna(value='<Null>')\n",
    "            # dups_shape = table[\"Name\"].nunique()\n",
    "            # dups_shape[dups_shape != 1].sum()\n",
    "            df.loc[i,\"Name\"] = f\"{os.path.basename(GIS_Feature)}_spa_{i}\"\n",
    "            df.loc[i,\"Radius\"] = radius\n",
    "            df.loc[i,\"Unique_Features\"] = table[\"Name\"].nunique()\n",
    "            arcpy.Delete_management(os.path.join(os.getcwd(),os.path.basename(temp_sp_names)+\".shp\"))\n",
    "            pbar.set_description(f\"With  {radius} Radius of search --> \")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def data_validation(self, gpd_SWMM, gpd_nearest, center, largest, closest, required_column_names):\n",
    "\n",
    "\n",
    "        df = gpd.GeoDataFrame(columns= gpd_nearest.columns)\n",
    "        pbar_1 = tqdm(range(len(gpd_nearest)))\n",
    "        for i in pbar_1:\n",
    "            for j in range(len(gpd_SWMM)):\n",
    "                if np.allclose(gpd_nearest.loc[i,\"Shape_Leng\"] , gpd_SWMM.loc[j, \"Shape_Leng\"], atol= 1) & np.allclose(gpd_nearest.loc[i,\"Angle\"] , gpd_SWMM.loc[j, \"Angle\"], atol= 1) & np.allclose(gpd_nearest.loc[i,\"N_Curve\"] , gpd_SWMM.loc[j, \"N_Curve\"], atol= 1) & np.allclose(gpd_nearest.loc[i,\"Vertices\"] , gpd_SWMM.loc[j, \"Vertices\"], atol= 1) & (gpd_nearest.loc[i, \"Name\"] == gpd_SWMM.loc[j, \"Name\"]):\n",
    "                    df = df.append(gpd_nearest.loc[i, :], ignore_index= True)\n",
    "                pbar_1.set_description(f\"Geopandas row {i} are being validated with SWMM row {j}\")\n",
    "                time.sleep(0.1)\n",
    "        gpd_nearest = df\n",
    "\n",
    "\n",
    "        duplicated = center[\"Name\"][center.Name.duplicated(keep= \"first\")].unique()\n",
    "\n",
    "\n",
    "        for k in range(len(duplicated)):\n",
    "            pbar_3 = tqdm(range(len(center)))\n",
    "            for i in pbar_3:\n",
    "                if center.loc[i ,\"Name\"] == duplicated[k]:\n",
    "\n",
    "                    for j in range(len(largest)):\n",
    "\n",
    "                        if np.allclose(center.loc[i,\"Shape_Leng\"] , largest.loc[j, \"Shape_Leng\"], atol= 1) & np.allclose(center.loc[i,\"Angle\"] , largest.loc[j, \"Angle\"], atol= 1) & np.allclose(center.loc[i,\"N_Curve\"] , largest.loc[j, \"N_Curve\"], atol= 1) & np.allclose(center.loc[i,\"Vertices\"] , largest.loc[j, \"Vertices\"], atol= 1):\n",
    "                            # center.drop(index = i, axis = \"columns\", inplace = True)\n",
    "                            # center = pd.concat([center, largest.loc[j, :]], join= \"inner\", ignore_index= True)\n",
    "                            center.loc[i, required_column_names] = largest.loc[j, required_column_names]\n",
    "                            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        else:\n",
    "                            if type(center.loc[i, \"Name\"]) == str:\n",
    "                                center.loc[i, \"Name\"] = None\n",
    "                        pbar_3.set_description(f\"Searching for finding data for {num2words(i+1, to = 'ordinal')} {duplicated[k]} in row {j} from LARGEST OVERLAP \")\n",
    "                        time.sleep(0.1)\n",
    "\n",
    "        duplicated = center[\"Name\"][center.Name.duplicated(keep= \"first\")].unique()\n",
    "\n",
    "\n",
    "        for k in range(len(duplicated)):\n",
    "            pbar_4 = tqdm(range(len(center)))\n",
    "            for i in pbar_4:\n",
    "                if center.loc[i ,\"Name\"] == duplicated[k]:\n",
    "                    for j in range(len(gpd_nearest)):\n",
    "\n",
    "                        if np.allclose(center.loc[i,\"Shape_Leng\"] , gpd_nearest.loc[j, \"Shape_Leng\"], atol= 1) & np.allclose(center.loc[i,\"Angle\"] , gpd_nearest.loc[j, \"Angle\"], atol= 1) & np.allclose(center.loc[i,\"N_Curve\"] , gpd_nearest.loc[j, \"N_Curve\"], atol= 1) & np.allclose(center.loc[i,\"Vertices\"] , gpd_nearest.loc[j, \"Vertices\"], atol= 1):\n",
    "                            # center.drop(index = i, axis = \"columns\", inplace = True)\n",
    "                            # center = pd.concat([center, gpd_nearest.loc[j, :]], join= \"inner\", ignore_index= True)\n",
    "                            center.loc[i, required_column_names] = gpd_nearest.loc[j, required_column_names]\n",
    "                            break\n",
    "                        else:\n",
    "                            if type(center.loc[i, \"Name\"]) == str:\n",
    "                                center.loc[i, \"Name\"] = None\n",
    "                        pbar_4.set_description(f\"Searching for finding data for {num2words(i+1, to = 'ordinal')} {duplicated[k]} in row {j} from GEOPANDAS NEAREST \")\n",
    "                        time.sleep(0.1)\n",
    "\n",
    "        duplicated = center[\"Name\"][center.Name.duplicated(keep= \"first\")].unique()\n",
    "\n",
    "        for k in range(len(duplicated)):\n",
    "            pbar_5 = tqdm(range(len(center)))\n",
    "            for i in pbar_5:\n",
    "                if center.loc[i ,\"Name\"] == duplicated[k]:\n",
    "\n",
    "                    for j in range(len(closest)):\n",
    "\n",
    "                        if np.allclose(center.loc[i,\"Shape_Leng\"] , closest.loc[j, \"Shape_Leng\"], atol= 1) & np.allclose(center.loc[i,\"Angle\"] , closest.loc[j, \"Angle\"], atol= 1) & np.allclose(center.loc[i,\"N_Curve\"] , closest.loc[j, \"N_Curve\"], atol= 1) & np.allclose(center.loc[i,\"Vertices\"] , closest.loc[j, \"Vertices\"], atol= 1):\n",
    "                            # center.drop(index = i, axis = \"columns\", inplace = True)\n",
    "                            # center = pd.concat([center, closest.loc[j, :]], join= \"inner\", ignore_index= True)\n",
    "                            center.loc[i, required_column_names] = closest.loc[j, required_column_names]\n",
    "                            break\n",
    "                        else:\n",
    "                            if type(center.loc[i, \"Name\"]) == str:\n",
    "                                center.loc[i, \"Name\"] = None\n",
    "                        pbar_5.set_description(f\"Searching for finding data for {num2words(i+1, to = 'ordinal')} {duplicated[k]} in row {j} from CLOSEST \")\n",
    "                        time.sleep(0.1)\n",
    "\n",
    "        return center\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def data_transfer(self):\n",
    "        arcpy.env.workspace = self.workspace\n",
    "        env.overwriteOutput = True\n",
    "\n",
    "        if arcpy.Exists(self.GIS_junctions):\n",
    "\n",
    "            df = self.spatial_join_points(self.GIS_junctions, self.SWMM_junctions)\n",
    "            opti_radius = df.loc[df.Unique_Features == df.loc[:,\"Unique_Features\"].max()][\"Radius\"]\n",
    "            opti_radius = np.random.choice(np.array(opti_radius))\n",
    "\n",
    "            arcpy.analysis.SpatialJoin(self.GIS_junctions, self.SWMM_junctions, os.path.join(self.workspace,\"GIS_junctions_spa\"),\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", \"CLOSEST\", opti_radius, '#')\n",
    "            arcpy.Delete_management(self.GIS_junctions)\n",
    "            arcpy.management.Rename(os.path.join(self.workspace,\"GIS_junctions_spa\"), self.GIS_junctions)\n",
    "\n",
    "\n",
    "        if arcpy.Exists(self.GIS_storages):\n",
    "            df = self.spatial_join_points(self.GIS_storages, self.SWMM_storages)\n",
    "            opti_radius = df.loc[df.Unique_Features == df.loc[:,\"Unique_Features\"].max()][\"Radius\"]\n",
    "            opti_radius = np.random.choice(np.array(opti_radius))\n",
    "\n",
    "            arcpy.analysis.SpatialJoin(self.GIS_storages, self.SWMM_storages, os.path.join(self.workspace,\"GIS_storages_spa\"),\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", \"CLOSEST\", opti_radius, '#')\n",
    "            arcpy.Delete_management(self.GIS_storages)\n",
    "            arcpy.management.Rename(os.path.join(self.workspace,\"GIS_storages_spa\"), self.GIS_storages)\n",
    "\n",
    "        if arcpy.Exists(self.GIS_dividers):\n",
    "            df = self.spatial_join_points(self.GIS_dividers, self.SWMM_dividers)\n",
    "            opti_radius = df.loc[df.Unique_Features == df.loc[:,\"Unique_Features\"].max()][\"Radius\"]\n",
    "            opti_radius = np.random.choice(np.array(opti_radius))\n",
    "\n",
    "            arcpy.analysis.SpatialJoin(self.GIS_dividers, self.SWMM_dividers, os.path.join(self.workspace,\"GIS_dividers_spa\"),\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", \"CLOSEST\", opti_radius, '#')\n",
    "            arcpy.Delete_management(self.GIS_dividers)\n",
    "            arcpy.management.Rename(os.path.join(self.workspace,\"GIS_dividers_spa\"), self.GIS_dividers)\n",
    "\n",
    "        if arcpy.Exists(self.GIS_outfalls):\n",
    "            df = self.spatial_join_points(self.GIS_outfalls, self.SWMM_outfalls)\n",
    "            opti_radius = df.loc[df.Unique_Features == df.loc[:,\"Unique_Features\"].max()][\"Radius\"]\n",
    "            opti_radius = np.random.choice(np.array(opti_radius))\n",
    "\n",
    "            arcpy.analysis.SpatialJoin(self.GIS_outfalls, self.SWMM_outfalls, os.path.join(self.workspace,\"GIS_outfalls_spa\"),\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", \"CLOSEST\", opti_radius, '#')\n",
    "            arcpy.Delete_management(self.GIS_outfalls)\n",
    "            arcpy.management.Rename(os.path.join(self.workspace,\"GIS_outfalls_spa\"), self.GIS_outfalls)\n",
    "\n",
    "        if arcpy.Exists(self.GIS_conduits):\n",
    "\n",
    "            esri_methods = pd.Series([\"HAVE_THEIR_CENTER_IN\", \"LARGEST_OVERLAP\", \"CLOSEST\"])\n",
    "            output_names = pd.Series([\"center\", \"largest\", \"closest\"])\n",
    "            pbar = tqdm(range(esri_methods.size))\n",
    "            for i in pbar:\n",
    "                pbar.set_description(f\"GIS_Counduits by methode '{esri_methods[i]}' are being joined\")\n",
    "                df = self.spatial_join_lines(self.GIS_conduits, self.SWMM_conduits, esri_methods[i])\n",
    "                opti_radius = df.loc[df.Unique_Features == df.loc[:,\"Unique_Features\"].max()][\"Radius\"]\n",
    "                opti_radius = np.random.choice(np.array(opti_radius))\n",
    "\n",
    "                arcpy.analysis.SpatialJoin(self.GIS_conduits, self.SWMM_conduits, os.path.join(self.outWorkspace,output_names[i]),\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", esri_methods[i], opti_radius, '#')\n",
    "                arcpy.management.CalculateGeometryAttributes(os.path.join(self.outWorkspace,output_names[i]), [[\"Angle\", \"LINE_BEARING\"], [\"N_Curve\", \"CURVE_COUNT\"], [\"Vertices\", \"POINT_COUNT\"]])\n",
    "                arcpy.FeatureClassToShapefile_conversion(os.path.join(self.outWorkspace,output_names[i]), os.getcwd())\n",
    "                globals()[output_names[i]] = gpd.read_file(os.path.join(os.getcwd(), output_names[i])+\".shp\")\n",
    "                arcpy.Delete_management(os.path.join(os.getcwd(), output_names[i])+\".shp\")\n",
    "\n",
    "\n",
    "            arcpy.management.CalculateGeometryAttributes(self.SWMM_conduits, [[\"Shape_Leng\", \"LENGTH\"], [\"Angle\", \"LINE_BEARING\"], [\"N_Curve\", \"CURVE_COUNT\"], [\"Vertices\", \"POINT_COUNT\"]])\n",
    "            arcpy.FeatureClassToShapefile_conversion(self.GIS_conduits, os.getcwd())\n",
    "            gpd_SWMM_conduits = gpd.read_file(self.SWMM_conduits)\n",
    "            # return gpd_SWMM_conduits\n",
    "            gpd_GIS_conduits = gpd.read_file(os.path.join(os.getcwd(),\"GIS_conduits.shp\"))\n",
    "            gpd_nearest = gpd.sjoin_nearest(gpd_GIS_conduits, gpd_SWMM_conduits, \"left\", max_distance= 2, distance_col=\"distance\").reset_index()\n",
    "\n",
    "            gpd_nearest.drop(columns= [\"index_right\", \"Shape_Leng_right\"], inplace= True)\n",
    "            gpd_nearest.rename(columns= {\"Shape_Leng_left\":\"Shape_Leng\"}, inplace= True)\n",
    "\n",
    "            gpd_nearest.to_file(os.path.join(os.getcwd(), \"gpd_nearest.shp\"))\n",
    "            arcpy.management.CalculateGeometryAttributes(os.path.join(os.getcwd(), \"gpd_nearest.shp\"), [[\"Angle\", \"LINE_BEARING\"], [\"N_Curve\", \"CURVE_COUNT\"], [\"Vertices\", \"POINT_COUNT\"]])\n",
    "            gpd_nearest = gpd.read_file(os.path.join(os.getcwd(), \"gpd_nearest.shp\"))\n",
    "            arcpy.Delete_management(os.path.join(os.getcwd(), \"gpd_nearest.shp\"))\n",
    "\n",
    "            conduits_required_column_names = ['Name',\n",
    "                                              'FromNode',\n",
    "                                              'ToNode',\n",
    "                                              'Length',\n",
    "                                              'Roughness',\n",
    "                                              'InOffset',\n",
    "                                              'OutOffset',\n",
    "                                              'InitFlow',\n",
    "                                              'MaxFlow',\n",
    "                                              'Shape_1',\n",
    "                                              'Geom1',\n",
    "                                              'Geom2',\n",
    "                                              'Geom3',\n",
    "                                              'Geom4',\n",
    "                                              'Barrels',\n",
    "                                              'Culvert',\n",
    "                                              'Shp_Tr'\n",
    "                                              'nsct',\n",
    "                                              'Kentry',\n",
    "                                              'Kexit',\n",
    "                                              'Kavg',\n",
    "                                              'FlapGate',\n",
    "                                              'Seepage']\n",
    "\n",
    "            gpd.GeoDataFrame.to_file(self.data_validation(gpd_SWMM_conduits, gpd_nearest, center, largest, closest, conduits_required_column_names),os.path.join(os.getcwd(), \"final_spatial.shp\"))\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(os.path.join(os.getcwd(), \"final_spatial.shp\"), self.workspace, \"final_spatial\")\n",
    "            arcpy.Delete_management(os.path.join(os.getcwd(), \"final_spatial.shp\"))\n",
    "\n",
    "\n",
    "            arcpy.Delete_management(self.GIS_conduits)\n",
    "            arcpy.management.Rename(os.path.join(self.workspace,\"final_spatial\"), self.GIS_conduits)\n",
    "\n",
    "        if arcpy.Exists(self.GIS_orifices):\n",
    "\n",
    "            esri_methods = pd.Series([\"HAVE_THEIR_CENTER_IN\", \"LARGEST_OVERLAP\", \"CLOSEST\"])\n",
    "            output_names = pd.Series([\"center\", \"largest\", \"closest\"])\n",
    "            pbar = tqdm(range(esri_methods.size))\n",
    "            for i in pbar:\n",
    "                pbar.set_description(f\"GIS_orifices by methode '{esri_methods[i]}' are being joined\")\n",
    "                df = self.spatial_join_lines(self.GIS_orifices, self.SWMM_orifices, esri_methods[i])\n",
    "                opti_radius = df.loc[df.Unique_Features == df.loc[:,\"Unique_Features\"].max()][\"Radius\"]\n",
    "                opti_radius = np.random.choice(np.array(opti_radius))\n",
    "\n",
    "                arcpy.analysis.SpatialJoin(self.GIS_orifices, self.SWMM_orifices, os.path.join(self.outWorkspace,output_names[i]),\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", esri_methods[i], opti_radius, '#')\n",
    "                arcpy.management.CalculateGeometryAttributes(os.path.join(self.outWorkspace,output_names[i]), [[\"Angle\", \"LINE_BEARING\"], [\"N_Curve\", \"CURVE_COUNT\"], [\"Vertices\", \"POINT_COUNT\"]])\n",
    "                arcpy.FeatureClassToShapefile_conversion(os.path.join(self.outWorkspace,output_names[i]), os.getcwd())\n",
    "                globals()[output_names[i]] = gpd.read_file(os.path.join(os.getcwd(), output_names[i])+\".shp\")\n",
    "                arcpy.Delete_management(os.path.join(os.getcwd(), output_names[i])+\".shp\")\n",
    "\n",
    "\n",
    "            arcpy.management.CalculateGeometryAttributes(self.SWMM_orifices, [[\"Shape_Leng\", \"LENGTH\"], [\"Angle\", \"LINE_BEARING\"], [\"N_Curve\", \"CURVE_COUNT\"], [\"Vertices\", \"POINT_COUNT\"]])\n",
    "            arcpy.FeatureClassToShapefile_conversion(self.GIS_orifices, os.getcwd())\n",
    "            gpd_SWMM_orifices = gpd.read_file(self.SWMM_orifices)\n",
    "            # return gpd_SWMM_orifices\n",
    "            gpd_GIS_orifices = gpd.read_file(os.path.join(os.getcwd(),\"GIS_orifices.shp\"))\n",
    "            gpd_nearest = gpd.sjoin_nearest(gpd_GIS_orifices, gpd_SWMM_orifices, \"left\", max_distance= 2, distance_col=\"distance\").reset_index()\n",
    "\n",
    "            gpd_nearest.drop(columns= [\"index_right\", \"Shape_Leng_right\"], inplace= True)\n",
    "            gpd_nearest.rename(columns= {\"Shape_Leng_left\":\"Shape_Leng\"}, inplace= True)\n",
    "\n",
    "            gpd_nearest.to_file(os.path.join(os.getcwd(), \"gpd_nearest.shp\"))\n",
    "            arcpy.management.CalculateGeometryAttributes(os.path.join(os.getcwd(), \"gpd_nearest.shp\"), [[\"Angle\", \"LINE_BEARING\"], [\"N_Curve\", \"CURVE_COUNT\"], [\"Vertices\", \"POINT_COUNT\"]])\n",
    "            gpd_nearest = gpd.read_file(os.path.join(os.getcwd(), \"gpd_nearest.shp\"))\n",
    "            arcpy.Delete_management(os.path.join(os.getcwd(), \"gpd_nearest.shp\"))\n",
    "\n",
    "            orifices_required_column_names = ['Name',\n",
    "                                              'FromNode',\n",
    "                                              'ToNode',\n",
    "                                              'Type',\n",
    "                                              'InOffset',\n",
    "                                              'Qcoeff',\n",
    "                                              'FlapGate',\n",
    "                                              'CloseTime',\n",
    "                                              'Shape_1',\n",
    "                                              'Height',\n",
    "                                              'Width']\n",
    "\n",
    "            gpd.GeoDataFrame.to_file(self.data_validation(gpd_SWMM_orifices, gpd_nearest, center, largest, closest, orifices_required_column_names),os.path.join(os.getcwd(), \"final_spatial.shp\"))\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(os.path.join(os.getcwd(), \"final_spatial.shp\"), self.workspace, \"final_spatial\")\n",
    "            arcpy.Delete_management(os.path.join(os.getcwd(), \"final_spatial.shp\"))\n",
    "\n",
    "\n",
    "            arcpy.Delete_management(self.GIS_orifices)\n",
    "            arcpy.management.Rename(os.path.join(self.workspace,\"final_spatial\"), self.GIS_orifices)\n",
    "\n",
    "        if arcpy.Exists(self.GIS_outlets):\n",
    "\n",
    "            esri_methods = pd.Series([\"HAVE_THEIR_CENTER_IN\", \"LARGEST_OVERLAP\", \"CLOSEST\"])\n",
    "            output_names = pd.Series([\"center\", \"largest\", \"closest\"])\n",
    "            pbar = tqdm(range(esri_methods.size))\n",
    "            for i in pbar:\n",
    "                pbar.set_description(f\"GIS_outlets by methode '{esri_methods[i]}' are being joined\")\n",
    "                df = self.spatial_join_lines(self.GIS_outlets, self.SWMM_outlets, esri_methods[i])\n",
    "                opti_radius = df.loc[df.Unique_Features == df.loc[:,\"Unique_Features\"].max()][\"Radius\"]\n",
    "                opti_radius = np.random.choice(np.array(opti_radius))\n",
    "\n",
    "                arcpy.analysis.SpatialJoin(self.GIS_outlets, self.SWMM_outlets, os.path.join(self.outWorkspace,output_names[i]),\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", esri_methods[i], opti_radius, '#')\n",
    "                arcpy.management.CalculateGeometryAttributes(os.path.join(self.outWorkspace,output_names[i]), [[\"Angle\", \"LINE_BEARING\"], [\"N_Curve\", \"CURVE_COUNT\"], [\"Vertices\", \"POINT_COUNT\"]])\n",
    "                arcpy.FeatureClassToShapefile_conversion(os.path.join(self.outWorkspace,output_names[i]), os.getcwd())\n",
    "                globals()[output_names[i]] = gpd.read_file(os.path.join(os.getcwd(), output_names[i])+\".shp\")\n",
    "                arcpy.Delete_management(os.path.join(os.getcwd(), output_names[i])+\".shp\")\n",
    "\n",
    "\n",
    "            arcpy.management.CalculateGeometryAttributes(self.SWMM_outlets, [[\"Shape_Leng\", \"LENGTH\"], [\"Angle\", \"LINE_BEARING\"], [\"N_Curve\", \"CURVE_COUNT\"], [\"Vertices\", \"POINT_COUNT\"]])\n",
    "            arcpy.FeatureClassToShapefile_conversion(self.GIS_outlets, os.getcwd())\n",
    "            gpd_SWMM_outlets = gpd.read_file(self.SWMM_outlets)\n",
    "            # return gpd_SWMM_outlets\n",
    "            gpd_GIS_outlets = gpd.read_file(os.path.join(os.getcwd(),\"GIS_outlets.shp\"))\n",
    "            gpd_nearest = gpd.sjoin_nearest(gpd_GIS_outlets, gpd_SWMM_outlets, \"left\", max_distance= 2, distance_col=\"distance\").reset_index()\n",
    "\n",
    "            gpd_nearest.drop(columns= [\"index_right\", \"Shape_Leng_right\"], inplace= True)\n",
    "            gpd_nearest.rename(columns= {\"Shape_Leng_left\":\"Shape_Leng\"}, inplace= True)\n",
    "\n",
    "            gpd_nearest.to_file(os.path.join(os.getcwd(), \"gpd_nearest.shp\"))\n",
    "            arcpy.management.CalculateGeometryAttributes(os.path.join(os.getcwd(), \"gpd_nearest.shp\"), [[\"Angle\", \"LINE_BEARING\"], [\"N_Curve\", \"CURVE_COUNT\"], [\"Vertices\", \"POINT_COUNT\"]])\n",
    "            gpd_nearest = gpd.read_file(os.path.join(os.getcwd(), \"gpd_nearest.shp\"))\n",
    "            arcpy.Delete_management(os.path.join(os.getcwd(), \"gpd_nearest.shp\"))\n",
    "\n",
    "            outlets_required_column_names = ['Name',\n",
    "                                             'FromNode',\n",
    "                                             'ToNode',\n",
    "                                             'InOffset',\n",
    "                                             'RateCurve',\n",
    "                                             'Qcoeff',\n",
    "                                             'Qexpon',\n",
    "                                             'FlapGate',\n",
    "                                             'CurveName']\n",
    "\n",
    "            gpd.GeoDataFrame.to_file(self.data_validation(gpd_SWMM_outlets, gpd_nearest, center, largest, closest, outlets_required_column_names),os.path.join(os.getcwd(), \"final_spatial.shp\"))\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(os.path.join(os.getcwd(), \"final_spatial.shp\"), self.workspace, \"final_spatial\")\n",
    "            arcpy.Delete_management(os.path.join(os.getcwd(), \"final_spatial.shp\"))\n",
    "\n",
    "\n",
    "            arcpy.Delete_management(self.GIS_outlets)\n",
    "            arcpy.management.Rename(os.path.join(self.workspace,\"final_spatial\"), self.GIS_outlets)\n",
    "\n",
    "\n",
    "        if arcpy.Exists(self.GIS_pumps):\n",
    "\n",
    "            esri_methods = pd.Series([\"HAVE_THEIR_CENTER_IN\", \"LARGEST_OVERLAP\", \"CLOSEST\"])\n",
    "            output_names = pd.Series([\"center\", \"largest\", \"closest\"])\n",
    "            pbar = tqdm(range(esri_methods.size))\n",
    "            for i in pbar:\n",
    "                pbar.set_description(f\"GIS_pumps by methode '{esri_methods[i]}' are being joined\")\n",
    "                df = self.spatial_join_lines(self.GIS_pumps, self.SWMM_pumps, esri_methods[i])\n",
    "                opti_radius = df.loc[df.Unique_Features == df.loc[:,\"Unique_Features\"].max()][\"Radius\"]\n",
    "                opti_radius = np.random.choice(np.array(opti_radius))\n",
    "\n",
    "                arcpy.analysis.SpatialJoin(self.GIS_pumps, self.SWMM_pumps, os.path.join(self.outWorkspace,output_names[i]),\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", esri_methods[i], opti_radius, '#')\n",
    "                arcpy.management.CalculateGeometryAttributes(os.path.join(self.outWorkspace,output_names[i]), [[\"Angle\", \"LINE_BEARING\"], [\"N_Curve\", \"CURVE_COUNT\"], [\"Vertices\", \"POINT_COUNT\"]])\n",
    "                arcpy.FeatureClassToShapefile_conversion(os.path.join(self.outWorkspace,output_names[i]), os.getcwd())\n",
    "                globals()[output_names[i]] = gpd.read_file(os.path.join(os.getcwd(), output_names[i])+\".shp\")\n",
    "                arcpy.Delete_management(os.path.join(os.getcwd(), output_names[i])+\".shp\")\n",
    "\n",
    "\n",
    "            arcpy.management.CalculateGeometryAttributes(self.SWMM_pumps, [[\"Shape_Leng\", \"LENGTH\"], [\"Angle\", \"LINE_BEARING\"], [\"N_Curve\", \"CURVE_COUNT\"], [\"Vertices\", \"POINT_COUNT\"]])\n",
    "            arcpy.FeatureClassToShapefile_conversion(self.GIS_pumps, os.getcwd())\n",
    "            gpd_SWMM_pumps = gpd.read_file(self.SWMM_pumps)\n",
    "            # return gpd_SWMM_pumps\n",
    "            gpd_GIS_pumps = gpd.read_file(os.path.join(os.getcwd(),\"GIS_pumps.shp\"))\n",
    "            gpd_nearest = gpd.sjoin_nearest(gpd_GIS_pumps, gpd_SWMM_pumps, \"left\", max_distance= 2, distance_col=\"distance\").reset_index()\n",
    "\n",
    "            gpd_nearest.drop(columns= [\"index_right\", \"Shape_Leng_right\"], inplace= True)\n",
    "            gpd_nearest.rename(columns= {\"Shape_Leng_left\":\"Shape_Leng\"}, inplace= True)\n",
    "\n",
    "            gpd_nearest.to_file(os.path.join(os.getcwd(), \"gpd_nearest.shp\"))\n",
    "            arcpy.management.CalculateGeometryAttributes(os.path.join(os.getcwd(), \"gpd_nearest.shp\"), [[\"Angle\", \"LINE_BEARING\"], [\"N_Curve\", \"CURVE_COUNT\"], [\"Vertices\", \"POINT_COUNT\"]])\n",
    "            gpd_nearest = gpd.read_file(os.path.join(os.getcwd(), \"gpd_nearest.shp\"))\n",
    "            arcpy.Delete_management(os.path.join(os.getcwd(), \"gpd_nearest.shp\"))\n",
    "\n",
    "            pumps_required_column_names = ['Name',\n",
    "                                           'FromNode',\n",
    "                                           'ToNode',\n",
    "                                           'PumpCurve',\n",
    "                                           'Status',\n",
    "                                           'Startup',\n",
    "                                           'Shutoff']\n",
    "\n",
    "            gpd.GeoDataFrame.to_file(self.data_validation(gpd_SWMM_pumps, gpd_nearest, center, largest, closest, pumps_required_column_names),os.path.join(os.getcwd(), \"final_spatial.shp\"))\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(os.path.join(os.getcwd(), \"final_spatial.shp\"), self.workspace, \"final_spatial\")\n",
    "            arcpy.Delete_management(os.path.join(os.getcwd(), \"final_spatial.shp\"))\n",
    "\n",
    "\n",
    "            arcpy.Delete_management(self.GIS_pumps)\n",
    "            arcpy.management.Rename(os.path.join(self.workspace,\"final_spatial\"), self.GIS_pumps)\n",
    "\n",
    "\n",
    "        if arcpy.Exists(self.GIS_weirs):\n",
    "\n",
    "            esri_methods = pd.Series([\"HAVE_THEIR_CENTER_IN\", \"LARGEST_OVERLAP\", \"CLOSEST\"])\n",
    "            output_names = pd.Series([\"center\", \"largest\", \"closest\"])\n",
    "            pbar = tqdm(range(esri_methods.size))\n",
    "            for i in pbar:\n",
    "                pbar.set_description(f\"GIS_weirs by methode '{esri_methods[i]}' are being joined\")\n",
    "                df = self.spatial_join_lines(self.GIS_weirs, self.SWMM_weirs, esri_methods[i])\n",
    "                opti_radius = df.loc[df.Unique_Features == df.loc[:,\"Unique_Features\"].max()][\"Radius\"]\n",
    "                opti_radius = np.random.choice(np.array(opti_radius))\n",
    "\n",
    "                arcpy.analysis.SpatialJoin(self.GIS_weirs, self.SWMM_weirs, os.path.join(self.outWorkspace,output_names[i]),\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", esri_methods[i], opti_radius, '#')\n",
    "                arcpy.management.CalculateGeometryAttributes(os.path.join(self.outWorkspace,output_names[i]), [[\"Angle\", \"LINE_BEARING\"], [\"N_Curve\", \"CURVE_COUNT\"], [\"Vertices\", \"POINT_COUNT\"]])\n",
    "                arcpy.FeatureClassToShapefile_conversion(os.path.join(self.outWorkspace,output_names[i]), os.getcwd())\n",
    "                globals()[output_names[i]] = gpd.read_file(os.path.join(os.getcwd(), output_names[i])+\".shp\")\n",
    "                arcpy.Delete_management(os.path.join(os.getcwd(), output_names[i])+\".shp\")\n",
    "\n",
    "\n",
    "            arcpy.management.CalculateGeometryAttributes(self.SWMM_weirs, [[\"Shape_Leng\", \"LENGTH\"], [\"Angle\", \"LINE_BEARING\"], [\"N_Curve\", \"CURVE_COUNT\"], [\"Vertices\", \"POINT_COUNT\"]])\n",
    "            arcpy.FeatureClassToShapefile_conversion(self.GIS_weirs, os.getcwd())\n",
    "            gpd_SWMM_weirs = gpd.read_file(self.SWMM_weirs)\n",
    "            # return gpd_SWMM_weirs\n",
    "            gpd_GIS_weirs = gpd.read_file(os.path.join(os.getcwd(),\"GIS_weirs.shp\"))\n",
    "            gpd_nearest = gpd.sjoin_nearest(gpd_GIS_weirs, gpd_SWMM_weirs, \"left\", max_distance= 2, distance_col=\"distance\").reset_index()\n",
    "\n",
    "            gpd_nearest.drop(columns= [\"index_right\", \"Shape_Leng_right\"], inplace= True)\n",
    "            gpd_nearest.rename(columns= {\"Shape_Leng_left\":\"Shape_Leng\"}, inplace= True)\n",
    "\n",
    "            gpd_nearest.to_file(os.path.join(os.getcwd(), \"gpd_nearest.shp\"))\n",
    "            arcpy.management.CalculateGeometryAttributes(os.path.join(os.getcwd(), \"gpd_nearest.shp\"), [[\"Angle\", \"LINE_BEARING\"], [\"N_Curve\", \"CURVE_COUNT\"], [\"Vertices\", \"POINT_COUNT\"]])\n",
    "            gpd_nearest = gpd.read_file(os.path.join(os.getcwd(), \"gpd_nearest.shp\"))\n",
    "            arcpy.Delete_management(os.path.join(os.getcwd(), \"gpd_nearest.shp\"))\n",
    "\n",
    "            weirs_required_column_names = ['Name',\n",
    "                                           'FromNode',\n",
    "                                           'ToNode',\n",
    "                                           'Type',\n",
    "                                           'CrestHeigh',\n",
    "                                           'Qcoeff',\n",
    "                                           'FlapGate',\n",
    "                                           'EndContrac',\n",
    "                                           'EndCoeff',\n",
    "                                           'Surcharge',\n",
    "                                           'RoadWidth',\n",
    "                                           'RoadSurf',\n",
    "                                           'CoeffCurve',\n",
    "                                           'Height',\n",
    "                                           'Length',\n",
    "                                           'SideSlope']\n",
    "\n",
    "            gpd.GeoDataFrame.to_file(self.data_validation(gpd_SWMM_weirs, gpd_nearest, center, largest, closest, weirs_required_column_names),os.path.join(os.getcwd(), \"final_spatial.shp\"))\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(os.path.join(os.getcwd(), \"final_spatial.shp\"), self.workspace, \"final_spatial\")\n",
    "            arcpy.Delete_management(os.path.join(os.getcwd(), \"final_spatial.shp\"))\n",
    "\n",
    "\n",
    "            arcpy.Delete_management(self.GIS_weirs)\n",
    "            arcpy.management.Rename(os.path.join(self.workspace,\"final_spatial\"), self.GIS_weirs)\n",
    "\n",
    "\n",
    "    def fill_null_values(self):\n",
    "\n",
    "        arcpy.env.workspace = self.workspace\n",
    "        env.overwriteOutput = True\n",
    "\n",
    "\n",
    "        for i in range(len(self.GIS_Points)):\n",
    "            arcpy.FeatureClassToShapefile_conversion(os.path.join(self.workspace, self.GIS_Points[i]), os.getcwd())\n",
    "            gdf = gpd.read_file(os.path.join(os.getcwd(), self.GIS_Points[i]+\".shp\"))\n",
    "            pbar = tqdm(range(0, gdf[\"Name\"].isna().sum()))\n",
    "            for row in pbar:\n",
    "                pbar.set_description(f\"Filling NA/Null values of {self.GIS_Points[i]} with UN_{self.GIS_Points[i][4:8]}_{row}\")\n",
    "                time.sleep(0.1)\n",
    "                gdf[\"Name\"].fillna(f\"UN_{self.GIS_Points[i][4:]}_{row+1}\", limit=1,inplace=True)\n",
    "            gdf.to_file(os.path.join(os.getcwd(), self.GIS_Points[i]+\".shp\"))\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(os.path.join(os.getcwd(), self.GIS_Points[i]+\".shp\"), self.workspace, self.GIS_Points[i])\n",
    "\n",
    "\n",
    "        for i in range(len(self.GIS_Lines)):\n",
    "            arcpy.FeatureClassToShapefile_conversion(os.path.join(self.workspace, self.GIS_Lines[i]), os.getcwd())\n",
    "            gdf = gpd.read_file(os.path.join(os.getcwd(), self.GIS_Lines[i]+\".shp\"))\n",
    "            pbar = tqdm(range(0, gdf[\"Name\"].isna().sum()))\n",
    "            for row in pbar:\n",
    "                pbar.set_description(f\"Filling NA/Null values of {self.GIS_Lines[i]} with UN_{self.GIS_Lines[i][4:8]}_{row}\")\n",
    "                time.sleep(0.1)\n",
    "                gdf[\"Name\"].fillna(f\"UN_{self.GIS_Lines[i][4:]}_{row+1}\", limit=1,inplace=True)\n",
    "            gdf.to_file(os.path.join(os.getcwd(), self.GIS_Lines[i]+\".shp\"))\n",
    "            arcpy.FeatureClassToFeatureClass_conversion(os.path.join(os.getcwd(), self.GIS_Lines[i]+\".shp\"), self.workspace, self.GIS_Lines[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def assigning_FromNode_and_ToNode(self):\n",
    "\n",
    "        arcpy.env.workspace = self.workspace\n",
    "        env.overwriteOutput = True\n",
    "\n",
    "        for i in range(len(self.GIS_Lines)):\n",
    "            arcpy.management.FeatureVerticesToPoints(os.path.join(self.workspace, self.GIS_Lines[i]), os.path.join(self.outWorkspace, self.GIS_Lines[i]+\"_start\"), \"START\")\n",
    "            arcpy.management.FeatureVerticesToPoints(os.path.join(self.workspace, self.GIS_Lines[i]), os.path.join(self.outWorkspace, self.GIS_Lines[i]+\"_end\"), \"END\")\n",
    "            arcpy.FeatureClassToShapefile_conversion(os.path.join(self.outWorkspace, self.GIS_Lines[i]+\"_start\"), os.getcwd())\n",
    "            arcpy.FeatureClassToShapefile_conversion(os.path.join(self.outWorkspace, self.GIS_Lines[i]+\"_end\"), os.getcwd())\n",
    "            start = gpd.read_file(os.path.join(os.getcwd(), self.GIS_Lines[i]+\"_start.shp\"))\n",
    "            end =  gpd.read_file(os.path.join(os.getcwd(), self.GIS_Lines[i]+\"_end.shp\"))\n",
    "            start.drop(start.columns.drop([\"Name\", \"geometry\"]), axis= \"columns\", inplace=True)\n",
    "            end.drop(end.columns.drop([\"Name\", \"geometry\"]), axis= \"columns\", inplace=True)\n",
    "            start.to_file(os.path.join(os.getcwd(), \"start.shp\"))\n",
    "            end.to_file(os.path.join(os.getcwd(), \"end.shp\"))\n",
    "\n",
    "\n",
    "            if arcpy.Exists(self.GIS_junctions):\n",
    "                arcpy.FeatureClassToShapefile_conversion(self.GIS_junctions, os.getcwd())\n",
    "                gpd_junctions = gpd.read_file(os.path.join(os.getcwd(), \"GIS_junctions.shp\"))\n",
    "                gpd_junctions.drop(gpd_junctions.columns.drop([\"Name\", \"geometry\"]), axis= \"columns\", inplace=True)\n",
    "                gpd_junctions.rename(columns={\"Name\":\"FromNode\"}, inplace=True)\n",
    "                gpd_junctions.to_file(os.path.join(os.getcwd(), \"gpd_junctions.shp\"))\n",
    "                # df = self.spatial_join_points(os.path.join(os.getcwd(), \"start.shp\"), os.path.join(os.getcwd(), \"gpd_junctions.shp\"))\n",
    "                # opti_radius = df.loc[df.Unique_Features == df.loc[:,\"Unique_Features\"].max()][\"Radius\"]\n",
    "                # opti_radius = np.random.choice(np.array(opti_radius))\n",
    "\n",
    "                arcpy.analysis.SpatialJoin(os.path.join(os.getcwd(), \"start.shp\"), os.path.join(os.getcwd(), \"gpd_junctions.shp\"), os.path.join(self.outWorkspace,\"GIS_junctions_spa\"),\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", \"CLOSEST\", \"2 FEET\", '#')\n",
    "                arcpy.Delete_management(os.path.join(os.getcwd(), \"start.shp\"))\n",
    "                arcpy.Delete_management(os.path.join(self.outWorkspace, \"start\"))\n",
    "                arcpy.management.Rename(os.path.join(self.outWorkspace,\"GIS_junctions_spa\"), os.path.join(self.outWorkspace, \"start\"))\n",
    "                arcpy.FeatureClassToShapefile_conversion(os.path.join(self.outWorkspace, \"start\"), os.getcwd())\n",
    "                arcpy.DeleteField_management(os.path.join(os.getcwd(), \"start.shp\"), \"FromNode\")\n",
    "                break\n",
    "\n",
    "\n",
    "                gpd_junctions = gpd.read_file(os.path.join(os.getcwd(), \"GIS_junctions.shp\"))\n",
    "                gpd_junctions.drop(gpd_junctions.columns.drop([\"Name\", \"geometry\"]), axis= \"columns\", inplace=True)\n",
    "                gpd_junctions.rename(columns={\"Name\":\"ToNode\"}, inplace=True)\n",
    "                gpd_junctions.to_file(os.path.join(os.getcwd(), \"gpd_junctions.shp\"))\n",
    "                # df = self.spatial_join_points(os.path.join(os.getcwd(), \"end.shp\"), os.path.join(os.getcwd(), \"gpd_junctions.shp\"))\n",
    "                # opti_radius = df.loc[df.Unique_Features == df.loc[:,\"Unique_Features\"].max()][\"Radius\"]\n",
    "                # opti_radius = np.random.choice(np.array(opti_radius))\n",
    "\n",
    "                arcpy.analysis.SpatialJoin(os.path.join(os.getcwd(), \"end.shp\"), os.path.join(os.getcwd(), \"gpd_junctions.shp\"), os.path.join(self.outWorkspace,\"GIS_junctions_spa\"),\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", \"CLOSEST\", \"2 FEET\", '#')\n",
    "                arcpy.Delete_management(os.path.join(os.getcwd(), \"end.shp\"))\n",
    "                arcpy.Delete_management(os.path.join(self.outWorkspace, \"end\"))\n",
    "                arcpy.management.Rename(os.path.join(self.outWorkspace,\"GIS_junctions_spa\"), os.path.join(self.outWorkspace, \"end\"))\n",
    "                arcpy.FeatureClassToShapefile_conversion(os.path.join(self.outWorkspace, \"end\"), os.getcwd())\n",
    "                arcpy.DeleteField_management(os.path.join(os.getcwd(), \"end.shp\"), \"ToNode\")\n",
    "                arcpy.JoinField_management(self.GIS_Lines[i], \"Name\", os.path.join(os.getcwd(), \"start.shp\"), \"Name\", \"FromNode\")\n",
    "                arcpy.JoinField_management(self.GIS_Lines[i], \"Name\", os.path.join(os.getcwd(), \"end.shp\"), \"Name\", \"ToNode\")\n",
    "\n",
    "\n",
    "            if arcpy.Exists(self.GIS_storages):\n",
    "                arcpy.FeatureClassToShapefile_conversion(self.GIS_storages, os.getcwd())\n",
    "                gpd_storages = gpd.read_file(os.path.join(os.getcwd(), \"GIS_storages.shp\"))\n",
    "                gpd_storages.drop(gpd_storages.columns.drop([\"Name\", \"geometry\"]), axis= \"columns\", inplace=True)\n",
    "                gpd_storages.rename(columns={\"Name\":\"FromNode\"}, inplace=True)\n",
    "                gpd_storages.to_file(os.path.join(os.getcwd(), \"gpd_storages.shp\"))\n",
    "                # df = self.spatial_join_points(os.path.join(os.getcwd(), \"start.shp\"), os.path.join(os.getcwd(), \"gpd_storages.shp\"))\n",
    "                # opti_radius = df.loc[df.Unique_Features == df.loc[:,\"Unique_Features\"].max()][\"Radius\"]\n",
    "                # opti_radius = np.random.choice(np.array(opti_radius))\n",
    "\n",
    "                arcpy.analysis.SpatialJoin(os.path.join(os.getcwd(), \"start.shp\"), os.path.join(os.getcwd(), \"gpd_storages.shp\"), os.path.join(self.outWorkspace,\"GIS_storages_spa\"),\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", \"CLOSEST\", \"2 FEET\", '#')\n",
    "                arcpy.Delete_management(os.path.join(os.getcwd(), \"start.shp\"))\n",
    "                arcpy.Delete_management(os.path.join(self.outWorkspace, \"start\"))\n",
    "                arcpy.management.Rename(os.path.join(self.outWorkspace,\"GIS_storages_spa\"), os.path.join(self.outWorkspace, \"start\"))\n",
    "                arcpy.FeatureClassToShapefile_conversion(os.path.join(self.outWorkspace, \"start\"), os.getcwd())\n",
    "                arcpy.DeleteField_management(os.path.join(os.getcwd(), \"start.shp\"), \"FromNode\")\n",
    "\n",
    "\n",
    "                gpd_storages = gpd.read_file(os.path.join(os.getcwd(), \"GIS_storages.shp\"))\n",
    "                gpd_storages.drop(gpd_storages.columns.drop([\"Name\", \"geometry\"]), axis= \"columns\", inplace=True)\n",
    "                gpd_storages.rename(columns={\"Name\":\"ToNode\"}, inplace=True)\n",
    "                gpd_storages.to_file(os.path.join(os.getcwd(), \"gpd_storages.shp\"))\n",
    "                # df = self.spatial_join_points(os.path.join(os.getcwd(), \"end.shp\"), os.path.join(os.getcwd(), \"gpd_storages.shp\"))\n",
    "                # opti_radius = df.loc[df.Unique_Features == df.loc[:,\"Unique_Features\"].max()][\"Radius\"]\n",
    "                # opti_radius = np.random.choice(np.array(opti_radius))\n",
    "\n",
    "                arcpy.analysis.SpatialJoin(os.path.join(os.getcwd(), \"end.shp\"), os.path.join(os.getcwd(), \"gpd_storages.shp\"), os.path.join(self.outWorkspace,\"GIS_storages_spa\"),\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", \"CLOSEST\", \"2 FEET\", '#')\n",
    "                arcpy.Delete_management(os.path.join(os.getcwd(), \"end.shp\"))\n",
    "                arcpy.Delete_management(os.path.join(self.outWorkspace, \"end\"))\n",
    "                arcpy.management.Rename(os.path.join(self.outWorkspace,\"GIS_storages_spa\"), os.path.join(self.outWorkspace, \"end\"))\n",
    "                arcpy.FeatureClassToShapefile_conversion(os.path.join(self.outWorkspace, \"end\"), os.getcwd())\n",
    "                arcpy.DeleteField_management(os.path.join(os.getcwd(), \"end.shp\"), \"ToNode\")\n",
    "                arcpy.JoinField_management(self.GIS_Lines[i], \"Name\", os.path.join(os.getcwd(), \"start.shp\"), \"Name\", \"FromNode\")\n",
    "                arcpy.JoinField_management(self.GIS_Lines[i], \"Name\", os.path.join(os.getcwd(), \"end.shp\"), \"Name\", \"ToNode\")\n",
    "\n",
    "            if arcpy.Exists(self.GIS_dividers):\n",
    "                arcpy.FeatureClassToShapefile_conversion(self.GIS_dividers, os.getcwd())\n",
    "                gpd_dividers = gpd.read_file(os.path.join(os.getcwd(), \"GIS_dividers.shp\"))\n",
    "                gpd_dividers.drop(gpd_dividers.columns.drop([\"Name\", \"geometry\"]), axis= \"columns\", inplace=True)\n",
    "                gpd_dividers.rename(columns={\"Name\":\"FromNode\"}, inplace=True)\n",
    "                gpd_dividers.to_file(os.path.join(os.getcwd(), \"gpd_dividers.shp\"))\n",
    "                # df = self.spatial_join_points(os.path.join(os.getcwd(), \"start.shp\"), os.path.join(os.getcwd(), \"gpd_dividers.shp\"))\n",
    "                # opti_radius = df.loc[df.Unique_Features == df.loc[:,\"Unique_Features\"].max()][\"Radius\"]\n",
    "                # opti_radius = np.random.choice(np.array(opti_radius))\n",
    "\n",
    "                arcpy.analysis.SpatialJoin(os.path.join(os.getcwd(), \"start.shp\"), os.path.join(os.getcwd(), \"gpd_dividers.shp\"), os.path.join(self.outWorkspace,\"GIS_dividers_spa\"),\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", \"CLOSEST\", \"2 FEET\", '#')\n",
    "                arcpy.Delete_management(os.path.join(os.getcwd(), \"start.shp\"))\n",
    "                arcpy.Delete_management(os.path.join(self.outWorkspace, \"start\"))\n",
    "                arcpy.management.Rename(os.path.join(self.outWorkspace,\"GIS_dividers_spa\"), os.path.join(self.outWorkspace, \"start\"))\n",
    "                arcpy.FeatureClassToShapefile_conversion(os.path.join(self.outWorkspace, \"start\"), os.getcwd())\n",
    "                arcpy.DeleteField_management(os.path.join(os.getcwd(), \"start.shp\"), \"FromNode\")\n",
    "\n",
    "\n",
    "                gpd_dividers = gpd.read_file(os.path.join(os.getcwd(), \"GIS_dividers.shp\"))\n",
    "                gpd_dividers.drop(gpd_dividers.columns.drop([\"Name\", \"geometry\"]), axis= \"columns\", inplace=True)\n",
    "                gpd_dividers.rename(columns={\"Name\":\"ToNode\"}, inplace=True)\n",
    "                gpd_dividers.to_file(os.path.join(os.getcwd(), \"gpd_dividers.shp\"))\n",
    "                # df = self.spatial_join_points(os.path.join(os.getcwd(), \"end.shp\"), os.path.join(os.getcwd(), \"gpd_dividers.shp\"))\n",
    "                # opti_radius = df.loc[df.Unique_Features == df.loc[:,\"Unique_Features\"].max()][\"Radius\"]\n",
    "                # opti_radius = np.random.choice(np.array(opti_radius))\n",
    "\n",
    "                arcpy.analysis.SpatialJoin(os.path.join(os.getcwd(), \"end.shp\"), os.path.join(os.getcwd(), \"gpd_dividers.shp\"), os.path.join(self.outWorkspace,\"GIS_dividers_spa\"),\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", \"CLOSEST\", \"2 FEET\", '#')\n",
    "                arcpy.Delete_management(os.path.join(os.getcwd(), \"end.shp\"))\n",
    "                arcpy.Delete_management(os.path.join(self.outWorkspace, \"end\"))\n",
    "                arcpy.management.Rename(os.path.join(self.outWorkspace,\"GIS_dividers_spa\"), os.path.join(self.outWorkspace, \"end\"))\n",
    "                arcpy.FeatureClassToShapefile_conversion(os.path.join(self.outWorkspace, \"end\"), os.getcwd())\n",
    "                arcpy.DeleteField_management(os.path.join(os.getcwd(), \"end.shp\"), \"ToNode\")\n",
    "                arcpy.JoinField_management(self.GIS_Lines[i], \"Name\", os.path.join(os.getcwd(), \"start.shp\"), \"Name\", \"FromNode\")\n",
    "                arcpy.JoinField_management(self.GIS_Lines[i], \"Name\", os.path.join(os.getcwd(), \"end.shp\"), \"Name\", \"ToNode\")\n",
    "\n",
    "            if arcpy.Exists(self.GIS_outfalls):\n",
    "                arcpy.FeatureClassToShapefile_conversion(self.GIS_outfalls, os.getcwd())\n",
    "                gpd_outfalls = gpd.read_file(os.path.join(os.getcwd(), \"GIS_outfalls.shp\"))\n",
    "                gpd_outfalls.drop(gpd_outfalls.columns.drop([\"Name\", \"geometry\"]), axis= \"columns\", inplace=True)\n",
    "                gpd_outfalls.rename(columns={\"Name\":\"FromNode\"}, inplace=True)\n",
    "                gpd_outfalls.to_file(os.path.join(os.getcwd(), \"gpd_outfalls.shp\"))\n",
    "                # df = self.spatial_join_points(os.path.join(os.getcwd(), \"start.shp\"), os.path.join(os.getcwd(), \"gpd_outfalls.shp\"))\n",
    "                # opti_radius = df.loc[df.Unique_Features == df.loc[:,\"Unique_Features\"].max()][\"Radius\"]\n",
    "                # opti_radius = np.random.choice(np.array(opti_radius))\n",
    "\n",
    "                arcpy.analysis.SpatialJoin(os.path.join(os.getcwd(), \"start.shp\"), os.path.join(os.getcwd(), \"gpd_outfalls.shp\"), os.path.join(self.outWorkspace,\"GIS_outfalls_spa\"),\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", \"CLOSEST\", \"2 FEET\", '#')\n",
    "                arcpy.Delete_management(os.path.join(os.getcwd(), \"start.shp\"))\n",
    "                arcpy.Delete_management(os.path.join(self.outWorkspace, \"start\"))\n",
    "                arcpy.management.Rename(os.path.join(self.outWorkspace,\"GIS_outfalls_spa\"), os.path.join(self.outWorkspace, \"start\"))\n",
    "                arcpy.FeatureClassToShapefile_conversion(os.path.join(self.outWorkspace, \"start\"), os.getcwd())\n",
    "\n",
    "\n",
    "                gpd_outfalls = gpd.read_file(os.path.join(os.getcwd(), \"GIS_outfalls.shp\"))\n",
    "                gpd_outfalls.drop(gpd_outfalls.columns.drop([\"Name\", \"geometry\"]), axis= \"columns\", inplace=True)\n",
    "                gpd_outfalls.rename(columns={\"Name\":\"ToNode\"}, inplace=True)\n",
    "                gpd_outfalls.to_file(os.path.join(os.getcwd(), \"gpd_outfalls.shp\"))\n",
    "                # df = self.spatial_join_points(os.path.join(os.getcwd(), \"end.shp\"), os.path.join(os.getcwd(), \"gpd_outfalls.shp\"))\n",
    "                # opti_radius = df.loc[df.Unique_Features == df.loc[:,\"Unique_Features\"].max()][\"Radius\"]\n",
    "                # opti_radius = np.random.choice(np.array(opti_radius))\n",
    "\n",
    "                arcpy.analysis.SpatialJoin(os.path.join(os.getcwd(), \"end.shp\"), os.path.join(os.getcwd(), \"gpd_outfalls.shp\"), os.path.join(self.outWorkspace,\"GIS_outfalls_spa\"),\"JOIN_ONE_TO_ONE\", \"KEEP_ALL\",\"#\", \"CLOSEST\", \"2 FEET\", '#')\n",
    "                arcpy.Delete_management(os.path.join(os.getcwd(), \"end.shp\"))\n",
    "                arcpy.Delete_management(os.path.join(self.outWorkspace, \"end\"))\n",
    "                arcpy.management.Rename(os.path.join(self.outWorkspace,\"GIS_outfalls_spa\"), os.path.join(self.outWorkspace, \"end\"))\n",
    "                arcpy.FeatureClassToShapefile_conversion(os.path.join(self.outWorkspace, \"end\"), os.getcwd())\n",
    "\n",
    "            # arcpy.DeleteField_management(self.GIS_Lines[i], [\"FromNode\", \"ToNode\"])\n",
    "\n",
    "                arcpy.JoinField_management(self.GIS_Lines[i], \"Name\", os.path.join(os.getcwd(), \"start.shp\"), \"Name\", \"FromNode\")\n",
    "                arcpy.JoinField_management(self.GIS_Lines[i], \"Name\", os.path.join(os.getcwd(), \"end.shp\"), \"Name\", \"ToNode\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def backup(self):\n",
    "\n",
    "        arcpy.env.workspace = self.workspace\n",
    "\n",
    "        if os.path.exists(os.path.join(os.getcwd(), \"GIS_Backup\")):\n",
    "            shutil.rmtree(os.path.join(os.getcwd(), \"GIS_Backup\"))\n",
    "\n",
    "        if os.path.exists(os.path.join(os.getcwd(), \"SWMM_Backup\")):\n",
    "            shutil.rmtree(os.path.join(os.getcwd(), \"SWMM_Backup\"))\n",
    "\n",
    "        output_folder = os.path.join(os.getcwd(), \"GIS_Backup\")\n",
    "        shutil.copytree(self.workspace, output_folder, symlinks=False, ignore=None, ignore_dangling_symlinks=False)\n",
    "\n",
    "        shape_files = arcpy.ListFeatureClasses()\n",
    "        print(shape_files)\n",
    "\n",
    "        output_folder = os.path.join(os.getcwd(), \"SWMM_Backup\")\n",
    "        shutil.copytree(self.SWMM_dir, output_folder, symlinks=False, ignore=None, ignore_dangling_symlinks=False)\n",
    "        arcpy.env.workspace = self.SWMM_dir\n",
    "        shape_files = arcpy.ListFeatureClasses()\n",
    "        print(shape_files)\n",
    "\n",
    "        arcpy.env.workspace = self.workspace\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def undo(self):\n",
    "\n",
    "        if os.path.exists(self.workspace):\n",
    "            shutil.rmtree(self.workspace)\n",
    "\n",
    "        if os.path.exists(self.SWMM_dir):\n",
    "            shutil.rmtree(self.SWMM_dir)\n",
    "        source_folder = os.path.join(os.getcwd(), \"GIS_Backup\")\n",
    "        shutil.copytree(source_folder, self.workspace, symlinks=False, ignore=None, ignore_dangling_symlinks=False)\n",
    "\n",
    "\n",
    "        source_folder = os.path.join(os.getcwd(), \"SWMM_Backup\")\n",
    "        shutil.copytree(source_folder, self.SWMM_dir, symlinks=False, ignore=None, ignore_dangling_symlinks=False)\n",
    "        print(\"All files have been recovered\")\n",
    "\n",
    "        return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"text-align:center\"><span style=\"color:red\"><font size=\"140\"> <strong> Collecting user input <strong> </font></span></p>\n",
    "\n",
    "##### By running this block of code the user will be asked to enter the desired geodatabase Microsoft windows standard path. You may consider that to get the best result in this matter you want to make sure that your previous and unproccesed SWMM shape files along with your georefrenced GIS shapefiles are preferabely have been created in your geodatabase with the exact name as below. Otherwise you may need to change the functions in the code as compatible as your shapefiles which due to interruption in how the code organized at the first place any changing in the core functions is not recommended.\n",
    "<span style=\"color:green\">dknlndk</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T19:03:15.933589100Z",
     "start_time": "2023-09-13T19:03:15.916748200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  GIS Founded Shapefiles   Status SWMM Founded Shapefiles   status\n0          GIS_junctions  No data          SWMM_junctions  No data\n1           GIS_storages  No data           SWMM_storages  No data\n2           GIS_conduits  No data           SWMM_conduits  No data\n3           GIS_dividers  No data           SWMM_dividers  No data\n4           GIS_outfalls  No data           SWMM_outfalls  No data\n5           GIS_orifices  No data           SWMM_orifices  No data\n6            GIS_outlets  No data            SWMM_outlets  No data\n7              GIS_pumps  No data              SWMM_pumps  No data\n8              GIS_weirs  No data              SWMM_weirs  No data\n9      GIS_subcatchments  No data      SWMM_subcatchments  No data",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GIS Founded Shapefiles</th>\n      <th>Status</th>\n      <th>SWMM Founded Shapefiles</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GIS_junctions</td>\n      <td>No data</td>\n      <td>SWMM_junctions</td>\n      <td>No data</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GIS_storages</td>\n      <td>No data</td>\n      <td>SWMM_storages</td>\n      <td>No data</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GIS_conduits</td>\n      <td>No data</td>\n      <td>SWMM_conduits</td>\n      <td>No data</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GIS_dividers</td>\n      <td>No data</td>\n      <td>SWMM_dividers</td>\n      <td>No data</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GIS_outfalls</td>\n      <td>No data</td>\n      <td>SWMM_outfalls</td>\n      <td>No data</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>GIS_orifices</td>\n      <td>No data</td>\n      <td>SWMM_orifices</td>\n      <td>No data</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>GIS_outlets</td>\n      <td>No data</td>\n      <td>SWMM_outlets</td>\n      <td>No data</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>GIS_pumps</td>\n      <td>No data</td>\n      <td>SWMM_pumps</td>\n      <td>No data</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>GIS_weirs</td>\n      <td>No data</td>\n      <td>SWMM_weirs</td>\n      <td>No data</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>GIS_subcatchments</td>\n      <td>No data</td>\n      <td>SWMM_subcatchments</td>\n      <td>No data</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GeoDatabase = r\"C:\\Users\\mxa7870\\OneDrive - University of Texas at Arlington\\Documents\\ArcGIS\\Projects\\test\\test.gdb\"\n",
    "SWMM_Directory = r\"C:\\Users\\mxa7870\\OneDrive - University of Texas at Arlington\\UTA\\Office\\GIS to SWMM model\\Defult\"\n",
    "project = GIS_To_SWMM(GeoDatabase,SWMM_Directory)\n",
    "project.read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T15:21:29.287323600Z",
     "start_time": "2023-09-13T15:21:29.074336Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'project' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mproject\u001B[49m\u001B[38;5;241m.\u001B[39mGIS_Points[\u001B[38;5;241m3\u001B[39m][\u001B[38;5;241m4\u001B[39m:\u001B[38;5;241m8\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'project' is not defined"
     ]
    }
   ],
   "source": [
    "project.GIS_Points[3][4:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"text-align:center\"><span style=\"color:red\"><font size=\"140\"> <strong> Consistent Lines <strong> </font></span></p>\n",
    "\n",
    "##### This function effectively takes 3 steps to get rid of inconsitent conduits or pipe lines in your case study shapefiles. unsplitting the lines means make them entrierly consistent which from end to end till a tilting happens which is not throughly what were being looked for, so after this step a speration by our point shapeflie align with lines will take place which make the data ready for the next block of code.\n",
    "<span style=\"color:green\"><strong>parameters:\n",
    "1) Line Shape-file: By default this argument has been set to lines which is your shapefile's name in your main GIS Geodatabase\n",
    "2) Point Shape-file: By default this argument has been set to lines which is your shapefile's name in your main GIS Geodatabase\n",
    "3) Snapexc Radius: you want to have all the points as near as less than `1 Feet` to the vericices of the lines so a snap tool before anything else would be helpful. If you experienced any problem over the running of this block such as not splitting the lines in the desired pin points try to change the snap radius parameter until you get the desired results.\n",
    "<strong></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.consistent_lines(line_series = project.GIS_Lines,\n",
    "                         point_series = project.GIS_Points,\n",
    "                         Snap_Radius = \"30 Feet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.backup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "project.shift_features(FID_List_Moving = \"Feature 0\",\n",
    "                       FID_List_Staying = \"Feature 1\",\n",
    "                       SWMM_Nodes = project.SWMM_junctions,\n",
    "                       GIS_Nodes =  project.GIS_junctions,\n",
    "                       rest =      [project.SWMM_storages,\n",
    "                                    project.SWMM_conduits,\n",
    "                                    project.SWMM_dividers,\n",
    "                                    project.SWMM_outfalls,\n",
    "                                    project.SWMM_orifices,\n",
    "                                    project.SWMM_outlets,\n",
    "                                    project.SWMM_pumps,\n",
    "                                    project.SWMM_weirs,\n",
    "                                    project.SWMM_subcatchments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.undo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"text-align:center\"><span style=\"color:red\"><font size=\"140\"> <strong> Data transfer (Spatial Join) <strong> </font></span></p>\n",
    "\n",
    "##### This function effectively takes 3 steps to get rid of inconsitent conduits or pipe lines in your case study shapefiles. unsplitting the lines means make them entrierly consistent which from end to end till a tilting happens which is not throughly what were being looked for, so after this step a speration by our point shapeflie align with lines will take place which make the data ready for the next block of code.\n",
    "<span style=\"color:green\"><strong>parameters:\n",
    "1) Line Shape-file: By default this argument has been set to lines which is your shapefile's name in your main GIS Geodatabase\n",
    "2) Point Shape-file: By default this argument has been set to lines which is your shapefile's name in your main GIS Geodatabase\n",
    "3) Snap Radius: you want to have all the points as near as less than `1 Feet` to the vericices of the lines so a snap tool before anything else would be helpful. If you experienced any problem over the running of this block such as not splitting the lines in the desired pin points try to change the snap radius parameter until you get the desired results.\n",
    "<strong></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.backup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.data_transfer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.spatial_join_points(os.path.join(os.getcwd(), \"start.shp\"),os.path.join(os.getcwd(), \"gpd_junctions.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.GIS_junctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.SWMM_junctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(os.getcwd(), \"start.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(os.getcwd(), \"gpd_junctions.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"text-align:center\"><span style=\"color:red\"><font size=\"140\"> <strong> Filling the NA/Null values <strong> </font></span></p>\n",
    "\n",
    "##### This function effectively takes 3 steps to get rid of inconsitent conduits or pipe lines in your case study shapefiles. unsplitting the lines means make them entrierly consistent which from end to end till a tilting happens which is not throughly what were being looked for, so after this step a speration by our point shapeflie align with lines will take place which make the data ready for the next block of code.\n",
    "<span style=\"color:green\"><strong>parameters:\n",
    "1) Line Shape-file: By default this argument has been set to lines which is your shapefile's name in your main GIS Geodatabase\n",
    "2) Point Shape-file: By default this argument has been set to lines which is your shapefile's name in your main GIS Geodatabase\n",
    "3) Snap Radius: you want to have all the points as near as less than `1 Feet` to the vericices of the lines so a snap tool before anything else would be helpful. If you experienced any problem over the running of this block such as not splitting the lines in the desired pin points try to change the snap radius parameter until you get the desired results.\n",
    "<strong></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.fill_null_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Assigning vertices on all the conduits </span>\n",
    "\n",
    "As the reason has been elaborated in the section \"\"\n",
    " by running this block code, the last version of conduits that have been acquired from the previous block will be procced in the way that each line will gain a new assigned start and end node, then the information from the nearest node as in Nodes layer would be transferred to this new layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.assigning_FromNode_and_ToNode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.Exists(os.path.join(os.getcwd(), \"start.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.read_file(os.path.join(os.getcwd(), \"start.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.read_file(os.path.join(os.getcwd(), \"end.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mxa7870\\\\OneDrive - University of Texas at Arlington\\\\Documents\\\\ArcGIS\\\\Projects\\\\test\\\\test.gdb\\\\GIS_junctions'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.GIS_junctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mxa7870\\\\OneDrive - University of Texas at Arlington\\\\UTA\\\\Office\\\\GIS to SWMM model\\\\Defult\\\\SWMM_junctions.shp'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.SWMM_junctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mxa7870\\\\OneDrive - University of Texas at Arlington\\\\Pycharm projects\\\\GIS to SWMM model\\\\start.shp'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.getcwd(), \"start.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mxa7870\\\\OneDrive - University of Texas at Arlington\\\\Pycharm projects\\\\GIS to SWMM model\\\\gpd_junctions.shp'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.getcwd(), \"gpd_junctions.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"text-align:center\"><span style=\"color:red\"><font size=\"140\"> <strong> Filling the NA/Null values <strong> </font></span></p>\n",
    "\n",
    "##### This function effectively takes 3 steps to get rid of inconsitent conduits or pipe lines in your case study shapefiles. unsplitting the lines means make them entrierly consistent which from end to end till a tilting happens which is not throughly what were being looked for, so after this step a speration by our point shapeflie align with lines will take place which make the data ready for the next block of code.\n",
    "<span style=\"color:green\"><strong>parameters:\n",
    "1) Line Shape-file: By default this argument has been set to lines which is your shapefile's name in your main GIS Geodatabase\n",
    "2) Point Shape-file: By default this argument has been set to lines which is your shapefile's name in your main GIS Geodatabase\n",
    "3) Snap Radius: you want to have all the points as near as less than `1 Feet` to the vericices of the lines so a snap tool before anything else would be helpful. If you experienced any problem over the running of this block such as not splitting the lines in the desired pin points try to change the snap radius parameter until you get the desired results.\n",
    "<strong></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "project.fill_null_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Assigning vertices on all the conduits </span>\n",
    "\n",
    "As the reason has been elaborated in the section \"\"\n",
    " by running this block code, the last version of conduits that have been acquired from the previous block will be procced in the way that each line will gain a new assigned start and end node, then the information from the nearest node as in Nodes layer would be transferred to this new layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.assigning_FromNode_and_ToNode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.Exists(os.path.join(os.getcwd(), \"start.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Join_Count</th>\n",
       "      <th>TARGET_FID</th>\n",
       "      <th>Join_Cou_1</th>\n",
       "      <th>TARGET_F_1</th>\n",
       "      <th>Join_Cou_2</th>\n",
       "      <th>TARGET_F_2</th>\n",
       "      <th>Join_Cou_3</th>\n",
       "      <th>TARGET_F_3</th>\n",
       "      <th>Name</th>\n",
       "      <th>FromNode</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>W_1</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (311111.980 5996268.223)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Join_Count  TARGET_FID  Join_Cou_1  TARGET_F_1  Join_Cou_2  TARGET_F_2  \\\n",
       "0           0           0           0           0           0           0   \n",
       "\n",
       "   Join_Cou_3  TARGET_F_3 Name FromNode                        geometry  \n",
       "0           1           0  W_1     None  POINT (311111.980 5996268.223)  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpd.read_file(os.path.join(os.getcwd(), \"start.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Join_Count</th>\n",
       "      <th>TARGET_FID</th>\n",
       "      <th>Join_Cou_1</th>\n",
       "      <th>TARGET_F_1</th>\n",
       "      <th>Join_Cou_2</th>\n",
       "      <th>TARGET_F_2</th>\n",
       "      <th>Join_Cou_3</th>\n",
       "      <th>TARGET_F_3</th>\n",
       "      <th>Name</th>\n",
       "      <th>ToNode</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W_1</td>\n",
       "      <td>Out_2</td>\n",
       "      <td>POINT (311211.382 5996082.217)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Join_Count  TARGET_FID  Join_Cou_1  TARGET_F_1  Join_Cou_2  TARGET_F_2  \\\n",
       "0           0           0           1           0           0           0   \n",
       "\n",
       "   Join_Cou_3  TARGET_F_3 Name ToNode                        geometry  \n",
       "0           0           0  W_1  Out_2  POINT (311211.382 5996082.217)  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpd.read_file(os.path.join(os.getcwd(), \"end.shp\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
